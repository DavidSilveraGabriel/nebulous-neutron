---
title: "Machine Learning B√°sico en Python: Scikit-learn, Pipelines, M√©tricas y Evaluaci√≥n"
description: "Un tutorial completo sobre Machine Learning b√°sico en Python: Scikit-learn, pipelines b√°sicos, y m√©tricas de evaluaci√≥n para modelos de aprendizaje autom√°tico."
---

import { Card, CardGrid  } from '@astrojs/starlight/components';
import { Aside } from '@astrojs/starlight/components';
import { Badge } from '@astrojs/starlight/components';
import { Code } from '@astrojs/starlight/components';

<CardGrid>
  <Card title="¬°Aplica el Aprendizaje Autom√°tico!" icon="cpu-2">
    Aprende los conceptos b√°sicos de Machine Learning y c√≥mo aplicarlos con Scikit-learn.
  </Card>
  <Card title="Pipelines y Evaluaci√≥n" icon="filter">
    Explora c√≥mo crear pipelines y evaluar el rendimiento de tus modelos de Machine Learning.
  </Card>
</CardGrid>

<Aside type="note" title="Importante üìù">
    El Machine Learning es una herramienta poderosa para extraer conocimiento y hacer predicciones a partir de datos.
</Aside>

# Machine Learning B√°sico en Python: Introducci√≥n al Aprendizaje Autom√°tico

En este post, exploraremos los conceptos b√°sicos del Machine Learning (Aprendizaje Autom√°tico) en Python. Aprender√°s a utilizar Scikit-learn para construir modelos de clasificaci√≥n y regresi√≥n, c√≥mo usar pipelines para simplificar el flujo de trabajo, y c√≥mo evaluar el rendimiento de tus modelos con m√©tricas adecuadas. Cubriremos:

1.  **Scikit-learn:**  C√≥mo usar esta librer√≠a para crear modelos de Machine Learning.
2.  **Pipelines B√°sicos:**  C√≥mo crear pipelines para preprocesar y modelar datos.
3.  **M√©tricas y Evaluaci√≥n:** C√≥mo evaluar el rendimiento de tus modelos.

## 1. Scikit-learn <Badge text="La Librer√≠a Fundamental" variant="tip" />

Scikit-learn es una librer√≠a de Python muy popular para construir modelos de Machine Learning. Proporciona una amplia gama de herramientas para clasificaci√≥n, regresi√≥n, clustering, reducci√≥n de dimensionalidad y mucho m√°s.

### Instalaci√≥n

```bash
pip install scikit-learn
```

### Modelos de Clasificaci√≥n
Los modelos de clasificaci√≥n se utilizan para predecir la categor√≠a a la que pertenece una instancia.
*   **Logistic Regression:** Un modelo lineal para clasificaci√≥n binaria.
*   **Support Vector Machine (SVM):**  Un modelo que busca un hiperplano √≥ptimo para separar las clases.
*   **Decision Tree:** Un modelo que utiliza una estructura de √°rbol para tomar decisiones.
*   **Random Forest:** Un modelo basado en un conjunto de √°rboles de decisi√≥n.
*  **K-Nearest Neighbors (KNN):** Clasifica cada instancia con base en sus k vecinos mas cercanos.
```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Datos simulados de ejemplo
data = {
  "caracteristica_1": [1,2,3,4,5,6,7,8,9,10],
  "caracteristica_2": [10,9,8,7,6,5,4,3,2,1],
  "clase": [0,0,0,0,0,1,1,1,1,1
}
df = pd.DataFrame(data)
X = df[["caracteristica_1", "caracteristica_2"]]
y = df["clase"]
# Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalar los datos
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Logistic Regression
modelo_lr = LogisticRegression()
modelo_lr.fit(X_train, y_train)
y_pred_lr = modelo_lr.predict(X_test)
print(f"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_lr)}")

# SVM
modelo_svm = SVC()
modelo_svm.fit(X_train, y_train)
y_pred_svm = modelo_svm.predict(X_test)
print(f"SVM Accuracy: {accuracy_score(y_test, y_pred_svm)}")

# Decision Tree
modelo_dt = DecisionTreeClassifier()
modelo_dt.fit(X_train, y_train)
y_pred_dt = modelo_dt.predict(X_test)
print(f"Decision Tree Accuracy: {accuracy_score(y_test, y_pred_dt)}")

# Random Forest
modelo_rf = RandomForestClassifier()
modelo_rf.fit(X_train, y_train)
y_pred_rf = modelo_rf.predict(X_test)
print(f"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf)}")

# KNN
modelo_knn = KNeighborsClassifier()
modelo_knn.fit(X_train, y_train)
y_pred_knn = modelo_knn.predict(X_test)
print(f"KNN Accuracy: {accuracy_score(y_test, y_pred_knn)}")
```

### Modelos de Regresi√≥n
Los modelos de regresi√≥n se utilizan para predecir un valor num√©rico continuo.

*   **Linear Regression:** Un modelo lineal para predecir un valor.
*   **Polynomial Regression:** Un modelo lineal que usa una transformaci√≥n polin√≥mica de las variables de entrada.
*  **Decision Tree Regression:** Un modelo de √°rbol de decisi√≥n para predecir un valor continuo.
*  **Random Forest Regression:** Modelo basado en un conjunto de arboles de decision para regresi√≥n.
```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Datos simulados de ejemplo
data = {
  "caracteristica_1": [1,2,3,4,5,6,7,8,9,10],
  "caracteristica_2": [10,9,8,7,6,5,4,3,2,1],
  "valor": [20,18,16,14,12,10,8,6,4,2]
}
df = pd.DataFrame(data)
X = df[["caracteristica_1", "caracteristica_2"]]
y = df["valor"]
# Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalar los datos
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Linear Regression
modelo_lr = LinearRegression()
modelo_lr.fit(X_train, y_train)
y_pred_lr = modelo_lr.predict(X_test)
print(f"Linear Regression MSE: {mean_squared_error(y_test, y_pred_lr)}")

# Polynomial Regression
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

modelo_pr = LinearRegression()
modelo_pr.fit(X_train_poly, y_train)
y_pred_pr = modelo_pr.predict(X_test_poly)
print(f"Polynomial Regression MSE: {mean_squared_error(y_test, y_pred_pr)}")


# Decision Tree Regression
modelo_dt = DecisionTreeRegressor()
modelo_dt.fit(X_train, y_train)
y_pred_dt = modelo_dt.predict(X_test)
print(f"Decision Tree Regression MSE: {mean_squared_error(y_test, y_pred_dt)}")

# Random Forest Regression
modelo_rf = RandomForestRegressor()
modelo_rf.fit(X_train, y_train)
y_pred_rf = modelo_rf.predict(X_test)
print(f"Random Forest Regression MSE: {mean_squared_error(y_test, y_pred_rf)}")
```
<Aside type="note" title="Nota üìù">
   Scikit-learn proporciona una interfaz consistente para diferentes modelos de Machine Learning, facilitando su uso y comparaci√≥n.
</Aside>

## 2. Pipelines B√°sicos <Badge text="Organizando tu Flujo de Trabajo" variant="note" />

Los pipelines permiten encadenar m√∫ltiples pasos de preprocesamiento y modelado de datos en un √∫nico objeto, simplificando el flujo de trabajo y facilitando la validaci√≥n cruzada y la optimizaci√≥n de hiperpar√°metros.

### Creaci√≥n de Pipelines
* `Pipeline(steps)`: Crea un pipeline con una lista de pasos.
* Los pasos del pipeline deben ser objetos con m√©todos `fit` y `transform` (preprocesamiento) o con m√©todos `fit` y `predict` (modelos).
```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
# Datos simulados de ejemplo
data = {
  "caracteristica_1": [1,2,3,4,5,6,7,8,9,10],
  "caracteristica_2": [10,9,8,7,6,5,4,3,2,1],
  "clase": [0,0,0,0,0,1,1,1,1,1]
}
df = pd.DataFrame(data)
X = df[["caracteristica_1", "caracteristica_2"]]
y = df["clase"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Pipeline
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("model", LogisticRegression())
])
# Entrenar el pipeline
pipeline.fit(X_train, y_train)
# Hacer predicciones
y_pred = pipeline.predict(X_test)

print(f"Accuracy with pipeline: {accuracy_score(y_test, y_pred)}")

# Pipeline con Transformaci√≥n Polinomial
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("poly", PolynomialFeatures(degree=2)),
    ("model", LogisticRegression())
])
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
print(f"Accuracy with polynomial features: {accuracy_score(y_test, y_pred)}")
```
### Ventajas de usar Pipelines
*   **Organizaci√≥n:**  Unifica el flujo de trabajo de preprocesamiento y modelado.
*  **Reutilizaci√≥n:** Reutiliza los pipelines en diferentes conjuntos de datos.
* **Validaci√≥n cruzada:** Facilita la validaci√≥n cruzada y la optimizaci√≥n de hiperpar√°metros.

<Aside type="tip" title="Consejo ‚ú®">
   Utiliza pipelines para organizar y simplificar tu flujo de trabajo de Machine Learning, haciendo tu c√≥digo m√°s limpio y f√°cil de mantener.
</Aside>

## 3. M√©tricas y Evaluaci√≥n <Badge text="Midiendo el Rendimiento" variant="success" size="large" />

La evaluaci√≥n del rendimiento de los modelos es fundamental para saber qu√© tan bien est√°n aprendiendo y generalizando a nuevos datos. Scikit-learn proporciona varias m√©tricas de evaluaci√≥n.

### M√©tricas de Clasificaci√≥n

*   **Accuracy:** Proporci√≥n de predicciones correctas.

    ```python
    from sklearn.metrics import accuracy_score
    accuracy = accuracy_score(y_true, y_pred)
    ```

*   **Precision:** Proporci√≥n de verdaderos positivos sobre el total de positivos predichos.

    ```python
    from sklearn.metrics import precision_score
    precision = precision_score(y_true, y_pred)
    ```

*   **Recall (Sensibilidad):** Proporci√≥n de verdaderos positivos sobre el total de positivos reales.

    ```python
    from sklearn.metrics import recall_score
    recall = recall_score(y_true, y_pred)
    ```

*   **F1-score:** Media arm√≥nica entre precision y recall.

    ```python
    from sklearn.metrics import f1_score
    f1 = f1_score(y_true, y_pred)
    ```

*   **Confusion Matrix:** Matriz que muestra el n√∫mero de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.
    ```python
    from sklearn.metrics import confusion_matrix
    matrix = confusion_matrix(y_true, y_pred)
    ```
*   **Classification Report:** Retorna las m√©tricas precision, recall y f1-score para cada clase.

     ```python
    from sklearn.metrics import classification_report
    report = classification_report(y_true, y_pred)
    ```
### M√©tricas de Regresi√≥n
*   **Mean Squared Error (MSE):** Promedio de los errores cuadr√°ticos.

    ```python
    from sklearn.metrics import mean_squared_error
    mse = mean_squared_error(y_true, y_pred)
    ```

*   **Root Mean Squared Error (RMSE):** Ra√≠z cuadrada del MSE.

    ```python
    import numpy as np
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    ```

*   **Mean Absolute Error (MAE):** Promedio de los errores absolutos.

    ```python
    from sklearn.metrics import mean_absolute_error
    mae = mean_absolute_error(y_true, y_pred)
    ```

*   **R-squared (R2):**  Proporci√≥n de la varianza de la variable dependiente que es predecible a partir de las variables independientes.

    ```python
    from sklearn.metrics import r2_score
    r2 = r2_score(y_true, y_pred)
    ```
### Validaci√≥n Cruzada
*   La validaci√≥n cruzada divide los datos en m√∫ltiples conjuntos de entrenamiento y prueba para tener una estimaci√≥n m√°s robusta del rendimiento del modelo.
*  `cross_val_score(modelo, X, y, cv)`: Retorna una lista con el score para cada partici√≥n en la validaci√≥n cruzada.

    ```python
    from sklearn.model_selection import cross_val_score, KFold
    from sklearn.linear_model import LogisticRegression
    from sklearn.datasets import load_iris

    iris = load_iris()
    X, y = iris.data, iris.target
    model = LogisticRegression()
    cv = KFold(n_splits=5) # se crea un objeto para definir la estrategia de validaci√≥n cruzada.

    scores = cross_val_score(model, X, y, cv=cv)
    print(scores) # [0.96666667 1.         0.93333333 0.96666667 1.        ]
    print(scores.mean()) # 0.9733333333333334
    ```

<Aside type="caution" title="Precauci√≥n ‚ö†Ô∏è">
  La elecci√≥n de las m√©tricas de evaluaci√≥n depende del problema a resolver y los objetivos espec√≠ficos.
</Aside>

## Conclusi√≥n

El Machine Learning es una herramienta poderosa para extraer informaci√≥n y hacer predicciones a partir de datos. En este post, exploramos Scikit-learn, pipelines b√°sicos, y m√©tricas de evaluaci√≥n. ¬°Ahora tienes las herramientas para construir y evaluar modelos de Machine Learning en Python!

<Badge text="¬°Sigue Aprendiendo!" variant="success" size="large" />

En el pr√≥ximo post, exploraremos Desarrollo Web con FastAPI, Django y Flask.

import { LinkButton } from '@astrojs/starlight/components';

<LinkButton
  href="/docs/Python-Master-Course/intro"
  variant="primary"
  icon="arrow-left"
  iconPlacement="start"
>
  Volver al Inicio del Curso
</LinkButton>
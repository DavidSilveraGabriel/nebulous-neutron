---
title: "Concurrencia y Paralelismo en Python: GIL, Threading, Multiprocessing, async/await, Queues y Pools"
description: "Un tutorial completo sobre concurrencia y paralelismo en Python: GIL y su impacto, threading y race conditions, multiprocessing, async/await, queues y pools."
---

import { Card, CardGrid  } from '@astrojs/starlight/components';
import { Aside } from '@astrojs/starlight/components';
import { Badge } from '@astrojs/starlight/components';
import { Code } from '@astrojs/starlight/components';

<CardGrid>
  <Card title="¡Acelera tu Código!" icon="cpu">
    Aprende a ejecutar código de forma concurrente y paralela para mejorar el rendimiento de tus aplicaciones.
  </Card>
  <Card title="Manejo de Tareas Simultáneas" icon="layers">
    Explora cómo usar threads, procesos y programación asíncrona para realizar tareas de manera eficiente.
  </Card>
</CardGrid>

<Aside type="note" title="Importante 📝">
  La concurrencia y el paralelismo son esenciales para mejorar el rendimiento de aplicaciones que necesitan realizar tareas simultáneas.
</Aside>

# Concurrencia y Paralelismo en Python: Ejecutando Tareas en Simultáneo

En este post, exploraremos en detalle cómo usar la concurrencia y el paralelismo en Python. Aprenderás a utilizar threads, procesos, programación asíncrona, queues y pools para ejecutar código de forma eficiente y simultánea. Cubriremos:

1.  **GIL y su Impacto:** El Global Interpreter Lock y cómo afecta al threading.
2.  **Threading y Race Conditions:** Cómo usar threads y cómo evitar condiciones de carrera.
3.  **Multiprocessing:** Cómo usar procesos para aprovechar múltiples núcleos.
4.  **`async`/`await`:** Cómo utilizar la programación asíncrona.
5.  **Queues y Pools:** Herramientas para gestionar tareas concurrentes y paralelas.

## 1. GIL y su Impacto <Badge text="El Global Interpreter Lock" variant="tip" />

El Global Interpreter Lock (GIL) es un mecanismo de bloqueo que permite que solo un thread ejecute bytecode de Python a la vez. Esto tiene un impacto significativo en la forma en que se utilizan los threads en Python.

### Impacto del GIL
*   **Limita el paralelismo:** El GIL evita que los threads ejecuten código Python de forma paralela en múltiples núcleos de CPU.
*   **No afecta a tareas IO-bound:** El GIL no afecta al rendimiento de tareas que esperan por operaciones de entrada/salida (IO), como leer archivos o hacer peticiones de red.

### Cómo el GIL Impacta Threads
*  Mientras un thread ejecuta bytecode de Python, ningún otro thread puede hacerlo.
*  Solo se simula el paralelismo mediante el cambio rápido entre threads.
* Para tareas CPU-bound (tareas que requieren mucho procesamiento), los threads no proporcionan una mejora real en la velocidad, debido al GIL.

<Aside type="note" title="Nota 📝">
  El GIL no afecta el rendimiento de tareas IO-bound.
  Para tareas CPU-bound usar multiprocessing en lugar de threading.
</Aside>

## 2. Threading y Race Conditions <Badge text="Ejecución Concurrente" variant="note" />

El threading permite ejecutar múltiples threads (hilos) dentro de un mismo proceso. Sin embargo, el uso de threads puede llevar a condiciones de carrera si no se toman las precauciones necesarias.

### Threading

*  El modulo `threading` permite crear threads en Python.
*  `threading.Thread(target=funcion, args=(argumentos,))`: Crea un nuevo thread.
*  `thread.start()`: Inicia un thread.
*  `thread.join()`: Espera a que un thread finalice.

```python
import threading
import time

def tarea(nombre, tiempo):
   print(f"Iniciando tarea {nombre}")
   time.sleep(tiempo)
   print(f"Tarea {nombre} finalizada")

thread1 = threading.Thread(target=tarea, args=("Tarea 1", 2))
thread2 = threading.Thread(target=tarea, args=("Tarea 2", 1))
thread1.start()
thread2.start()
thread1.join()
thread2.join()
print("Todas las tareas han finalizado")
```

### Race Conditions
Las condiciones de carrera ocurren cuando múltiples threads acceden y modifican el mismo recurso compartido (ej: una variable global) de forma concurrente, lo que puede resultar en resultados inesperados.

```python
import threading

contador = 0

def incrementar_contador():
    global contador
    for _ in range(1000000):
        contador += 1

thread1 = threading.Thread(target=incrementar_contador)
thread2 = threading.Thread(target=incrementar_contador)
thread1.start()
thread2.start()
thread1.join()
thread2.join()
print(f"Contador: {contador}") # El valor no siempre sera 2000000

```

### Locks
Los locks (bloqueos) permiten sincronizar el acceso a recursos compartidos, evitando condiciones de carrera.
*   `threading.Lock()`: Crea un lock.
*   `lock.acquire()`: Adquiere el lock (bloquea el acceso).
*   `lock.release()`: Libera el lock (permite el acceso).

```python
import threading

contador = 0
lock = threading.Lock()

def incrementar_contador():
    global contador
    for _ in range(1000000):
        with lock: # Adquiere y libera el lock automáticamente al salir del contexto
           contador += 1

thread1 = threading.Thread(target=incrementar_contador)
thread2 = threading.Thread(target=incrementar_contador)
thread1.start()
thread2.start()
thread1.join()
thread2.join()
print(f"Contador: {contador}") # El valor siempre será 2000000

```
## 3. Multiprocessing <Badge text="Paralelismo Real" variant="success" size="large" />

El multiprocessing permite crear múltiples procesos que se ejecutan de forma paralela, evitando las limitaciones del GIL, ideal para tareas CPU-bound.

### Multiprocessing

*   El modulo `multiprocessing` permite crear procesos.
*   `multiprocessing.Process(target=funcion, args=(argumentos,))`: Crea un nuevo proceso.
*   `process.start()`: Inicia un proceso.
*   `process.join()`: Espera a que un proceso finalice.

```python
import multiprocessing
import time

def tarea(nombre, tiempo):
   print(f"Iniciando tarea {nombre} en proceso {multiprocessing.current_process().name}")
   time.sleep(tiempo)
   print(f"Tarea {nombre} finalizada en proceso {multiprocessing.current_process().name}")

proceso1 = multiprocessing.Process(target=tarea, args=("Tarea 1", 2))
proceso2 = multiprocessing.Process(target=tarea, args=("Tarea 2", 1))
proceso1.start()
proceso2.start()
proceso1.join()
proceso2.join()
print("Todas las tareas han finalizado")
```
### Comunicación entre procesos
Para compartir información entre procesos, se pueden usar mecanismos de comunicación como queues o pipes.
*   **`multiprocessing.Queue()`:** Crea una queue para comunicación entre procesos.

```python
import multiprocessing

def productor(queue, cantidad):
    for i in range(cantidad):
        queue.put(i)
        print(f"Productor: añadiendo {i}")
    queue.put(None) # Señal de finalización

def consumidor(queue):
   while True:
    item = queue.get()
    if item is None:
        print("Consumidor: Finalizando")
        break
    print(f"Consumidor: Recibiendo {item}")

if __name__ == "__main__":
    queue = multiprocessing.Queue()
    proceso_productor = multiprocessing.Process(target=productor, args=(queue, 5))
    proceso_consumidor = multiprocessing.Process(target=consumidor, args=(queue,))

    proceso_productor.start()
    proceso_consumidor.start()
    proceso_productor.join()
    proceso_consumidor.join()

```

## 4. `async`/`await` <Badge text="Programación Asíncrona" variant="tip" />

La programación asíncrona permite ejecutar código de forma concurrente usando una sola thread, siendo especialmente útil para tareas IO-bound.

### `async` y `await`

*   `async def`: Define una función asíncrona.
*   `await`: Espera a que una función asíncrona termine.
*  Para ejecutar funciones async se debe usar el modulo `asyncio`
    *  `asyncio.run(funcion)`: Ejecuta la funcion principal asíncrona.
    *  `asyncio.sleep(segundos)`: Suspende la ejecución durante un tiempo especificado (asíncronamente).

```python
import asyncio
import time

async def tarea(nombre, tiempo):
   print(f"Iniciando tarea {nombre}")
   await asyncio.sleep(tiempo)
   print(f"Tarea {nombre} finalizada")

async def main():
    inicio = time.time()
    await asyncio.gather(
       tarea("Tarea 1", 2),
       tarea("Tarea 2", 1)
    )
    fin = time.time()
    print(f"Tiempo total: {fin - inicio}")


asyncio.run(main())

```

### Ventajas de la Programación Asíncrona
*   **Eficiencia:** Permite realizar tareas IO-bound de manera concurrente en un solo thread.
*   **Escalabilidad:** Es más eficiente para manejar un gran número de conexiones y tareas IO-bound.

<Aside type="caution" title="Precaución ⚠️">
    `async`/`await` no acelera tareas CPU-bound ya que se ejecutan en un solo thread.
</Aside>

## 5. Queues y Pools <Badge text="Gestión de Tareas" variant="note" />

Las queues y pools son herramientas que facilitan la gestión de tareas concurrentes y paralelas.

### Queues

Las queues permiten gestionar tareas en colas, donde cada thread o proceso puede tomar una tarea de la cola y procesarla.
*   `queue.Queue()`: Crea una cola para gestionar tareas en threading.
*   `queue.put(item)`: Inserta un item en la cola.
*   `queue.get()`:  Obtiene y remueve un item de la cola.

```python
import threading
import queue
import time

cola = queue.Queue()

def productor(cantidad):
   for i in range(cantidad):
      cola.put(i)
      time.sleep(0.1)
   cola.put(None) # Señal de finalización
def consumidor():
   while True:
      item = cola.get()
      if item is None:
        break
      print(f"Consumidor: recibiendo {item}")
thread_productor = threading.Thread(target=productor, args=(10,))
thread_consumidor = threading.Thread(target=consumidor)

thread_productor.start()
thread_consumidor.start()
thread_productor.join()
thread_consumidor.join()

```

### Pools

Los pools permiten reutilizar un conjunto de threads o procesos para ejecutar múltiples tareas.

*   `multiprocessing.Pool()`: Crea un pool de procesos.
*   `pool.apply(funcion, args)`: Ejecuta una funcion en un solo proceso del pool (bloqueante).
*   `pool.apply_async(funcion, args)`:  Ejecuta una funcion en un solo proceso del pool (no bloqueante).
*   `pool.map(funcion, iterable)`:  Ejecuta una funcion para cada elemento del iterable en distintos procesos.
*   `pool.close()`: Cierra el pool y termina la posibilidad de añadir mas tareas.
*   `pool.join()`: Espera a que todos los procesos del pool terminen.

```python
import multiprocessing

def calcular_cuadrado(numero):
    return numero**2

if __name__ == "__main__":
  with multiprocessing.Pool(processes=4) as pool:
    numeros = [1, 2, 3, 4, 5, 6, 7, 8
    resultados = pool.map(calcular_cuadrado, numeros)
    print(resultados) # [1, 4, 9, 16, 25, 36, 49, 64]
```

## Conclusión

La concurrencia y el paralelismo son fundamentales para construir aplicaciones de alto rendimiento en Python. En este post, exploramos el GIL, threads y race conditions, multiprocessing, `async`/`await`, y queues y pools. ¡Ahora puedes ejecutar tu código de manera simultánea y eficiente!

<Badge text="¡Sigue Optimizando!" variant="success" size="large" />

En el próximo post, exploraremos testing.

import { LinkButton } from '@astrojs/starlight/components';

<LinkButton
  href="/docs/Python-Master-Course/intro"
  variant="primary"
  icon="arrow-left"
  iconPlacement="start"
>
  Volver al Inicio del Curso
</LinkButton>